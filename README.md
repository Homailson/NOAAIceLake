# NOAA Ice Lake ğŸŒ¡ï¸â„ï¸

## VisÃ£o Geral
Pipeline completo de dados meteorolÃ³gicos que coleta, transforma e apresenta dados da NOAA (National Oceanic and Atmospheric Administration) usando uma arquitetura serverless moderna na AWS. O sistema processa dados climÃ¡ticos de estaÃ§Ãµes meteorolÃ³gicas brasileiras e os armazena em um data lake usando Apache Iceberg para anÃ¡lises avanÃ§adas.

## ğŸ—ï¸ Arquitetura

![noaa_arquitetura](/noaaiceberg_arc.jpeg)
![noaa_powerbidashboard](/noaaiceberg_dash.jpeg)

## ğŸ”„ Pipeline de Dados

### 1. **Camada de IngestÃ£o**
- **generatePeriods**: Gera perÃ­odos de coleta (padrÃ£o: mÃªs anterior)
- **getStationsResults**: Coleta mediÃ§Ãµes meteorolÃ³gicas da API NOAA
- **getStationsIds**: Extrai IDs Ãºnicos de estaÃ§Ãµes dos resultados
- **getStationsByIds**: ObtÃ©m metadados detalhados das estaÃ§Ãµes

### 2. **Camada de TransformaÃ§Ã£o**
- **resultsTransformation**: Converte dados brutos em tabelas Iceberg otimizadas
- **stationsTransformation**: Processa metadados de estaÃ§Ãµes para anÃ¡lise

### 3. **Camada de ApresentaÃ§Ã£o**
- **presentation**: Cria views agregadas para consultas analÃ­ticas

## ğŸ“Š Estrutura de Dados

### Raw Data (S3)
```
s3://noaaicelake/
â”œâ”€â”€ raw/
â”‚   â”œâ”€â”€ results/
â”‚   â”‚   â””â”€â”€ datatype={TMAX|TMIN|TAVG|PRCP}/
â”‚   â”‚       â””â”€â”€ year={YYYY}/month={MM}/day={DD}/
â”‚   â”‚           â””â”€â”€ data.json
â”‚   â””â”€â”€ stations/
â”‚       â”œâ”€â”€ metadata/stations_metadata.json
â”‚       â””â”€â”€ region={STATE}/stations_{YYYY-MM-DD}.json
â”œâ”€â”€ transformation/
â”‚   â”œâ”€â”€ daily_measurements/  # Tabela Iceberg
â”‚   â””â”€â”€ stations/           # Tabela Iceberg
â””â”€â”€ presentation/
    â”œâ”€â”€ monthly_avg_temp/   # Views agregadas
    â””â”€â”€ station_summary/
```

### Tabelas Iceberg

**transformed_results**
- `id` (PK): Identificador Ãºnico da mediÃ§Ã£o
- `station`: ID da estaÃ§Ã£o meteorolÃ³gica
- `date`: Data da mediÃ§Ã£o
- `tmax`, `tmin`, `tavg`: Temperaturas (Â°C)
- `prcp`: PrecipitaÃ§Ã£o (mm)
- Particionado por: `year`, `month`

**transformed_stations**
- `id` (PK): ID da estaÃ§Ã£o
- `name`: Nome da estaÃ§Ã£o
- `latitude`, `longitude`: Coordenadas
- `elevation`: Altitude
- `state`: Estado brasileiro
- `datacoverage`: Cobertura de dados
- Particionado por: `state`

## ğŸ› ï¸ Tecnologias

- **Python 3.11**: Linguagem principal
- **AWS Lambda**: ComputaÃ§Ã£o serverless
- **Amazon S3**: Data lake storage
- **Apache Iceberg**: Formato de tabela ACID
- **AWS Glue Catalog**: Metastore
- **DuckDB**: Engine de processamento
- **PyArrow**: ManipulaÃ§Ã£o de dados colunares
- **Docker**: ContainerizaÃ§Ã£o
- **Amazon ECR**: Registry de containers

## âš™ï¸ ConfiguraÃ§Ã£o

### VariÃ¡veis de Ambiente
```bash
# API NOAA
noaa_api_key=your_noaa_api_key
datatypes=["TMAX","TMIN","TAVG","PRCP"]

# AWS
S3_BUCKET=noaaicelake
BUCKET=noaaicelake
API_KEY=your_noaa_api_key

# Iceberg
PYICEBERG_CATALOG__GLUE__TYPE=glue
PYICEBERG_CATALOG__GLUE__URI=https://glue.us-east-1.amazonaws.com
PYICEBERG_CATALOG__GLUE__WAREHOUSE=s3://noaaicelake
```

### DependÃªncias
```txt
pyiceberg[s3fs,glue,pyarrow]
duckdb==1.2.2
requests
```

## ğŸš€ Deploy

### PrÃ©-requisitos
- AWS CLI configurado
- Docker instalado
- Chave API da NOAA CDO
- Bucket S3 criado

### ImplantaÃ§Ã£o Automatizada
```bash
# Executar deploy completo
./deploy.sh
```

O script automaticamente:
1. Cria repositÃ³rio ECR (se necessÃ¡rio)
2. ConstrÃ³i imagem Docker
3. Faz push para ECR
4. Atualiza todas as funÃ§Ãµes Lambda
5. Limpa imagens antigas

### FunÃ§Ãµes Lambda Criadas
- `generatePeriods`
- `getStationsResults`
- `getStationsIds`
- `getStationsByIds`
- `resultsTransformation`
- `stationsTransformation`
- `presentation`

## ğŸ“ˆ Uso

### ExecuÃ§Ã£o Manual
```python
# Gerar perÃ­odos
result = generate_periods_lambda({}, {})

# Coletar dados
result = get_stations_results_lambda({
    "start": "2024-11-01",
    "end": "2024-11-30"
}, {})
```

### Agendamento
Configure EventBridge para execuÃ§Ã£o automÃ¡tica mensal.

## ğŸ” Monitoramento

- **CloudWatch Logs**: Logs detalhados de cada Lambda
- **CloudWatch Metrics**: MÃ©tricas de execuÃ§Ã£o
- **S3 Metrics**: Uso de storage
- **Glue Catalog**: Metadados das tabelas

## ğŸ“‹ Tipos de Dados Coletados

- **TMAX**: Temperatura mÃ¡xima diÃ¡ria (Â°C)
- **TMIN**: Temperatura mÃ­nima diÃ¡ria (Â°C)
- **TAVG**: Temperatura mÃ©dia diÃ¡ria (Â°C)
- **PRCP**: PrecipitaÃ§Ã£o diÃ¡ria (mm)

## ğŸŒ Cobertura GeogrÃ¡fica

Foco em estaÃ§Ãµes meteorolÃ³gicas brasileiras com dados histÃ³ricos robustos.

## ğŸ”§ Desenvolvimento

### Estrutura do Projeto
```
NOAA_Ice_Lake/
â”œâ”€â”€ lambdas/
â”‚   â”œâ”€â”€ ingestion/
â”‚   â”‚   â”œâ”€â”€ modules/ingestion_utils/
â”‚   â”‚   â”œâ”€â”€ generate_periods.py
â”‚   â”‚   â”œâ”€â”€ get_stations_results.py
â”‚   â”‚   â”œâ”€â”€ get_stations_ids.py
â”‚   â”‚   â””â”€â”€ get_stations_by_ids.py
â”‚   â”œâ”€â”€ transformation/
â”‚   â”‚   â”œâ”€â”€ results_transformation.py
â”‚   â”‚   â””â”€â”€ stations_transformation.py
â”‚   â””â”€â”€ presentation/
â”‚       â””â”€â”€ presentation.py
â”œâ”€â”€ app.py
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ deploy.sh
â””â”€â”€ requirements-no-hash.txt
```

### Ambiente Local
```bash
# Criar ambiente virtual
python -m venv env
source env/bin/activate  # Linux/Mac
# ou
env\Scripts\activate     # Windows

# Instalar dependÃªncias
pip install -r requirements-no-hash.txt
```

## ğŸ“„ LicenÃ§a

Este projeto estÃ¡ disponÃ­vel sob os termos da licenÃ§a [MIT](https://opensource.org/licenses/MIT).

---

**Desenvolvido com â¤ï¸ para anÃ¡lise de dados meteorolÃ³gicos brasileiros**